<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Peter Bloomingdale">
<meta name="dcterms.date" content="2023-04-19">

<title>Peter’s Website - Tutorial for using OpenAI API for GPT-X Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GPQF9TMB2F"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-GPQF9TMB2F', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Peter’s Website</span>
    </a>
  </div>
          <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <div class="quarto-toggle-container">
                <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
            </div>
            <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Tutorial for using OpenAI API for GPT-X Models</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Peter Bloomingdale </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 19, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#obtain-the-code" id="toc-obtain-the-code" class="nav-link active" data-scroll-target="#obtain-the-code">Obtain the Code</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#prerequisites" id="toc-prerequisites" class="nav-link" data-scroll-target="#prerequisites">Prerequisites</a>
  <ul class="collapse">
  <li><a href="#openai-api-key-and-organization-id" id="toc-openai-api-key-and-organization-id" class="nav-link" data-scroll-target="#openai-api-key-and-organization-id">OpenAI API Key and Organization ID</a></li>
  <li><a href="#setting-up-the-secrets.py-file" id="toc-setting-up-the-secrets.py-file" class="nav-link" data-scroll-target="#setting-up-the-secrets.py-file">Setting Up the secrets.py File</a></li>
  </ul></li>
  <li><a href="#python-functions-overview" id="toc-python-functions-overview" class="nav-link" data-scroll-target="#python-functions-overview">Python Functions Overview</a>
  <ul class="collapse">
  <li><a href="#gpt-class" id="toc-gpt-class" class="nav-link" data-scroll-target="#gpt-class">GPT Class</a></li>
  <li><a href="#gpttxt-class" id="toc-gpttxt-class" class="nav-link" data-scroll-target="#gpttxt-class">GPTTXT Class</a></li>
  </ul></li>
  <li><a href="#using-the-functions" id="toc-using-the-functions" class="nav-link" data-scroll-target="#using-the-functions">Using the Functions</a>
  <ul class="collapse">
  <li><a href="#the-gpt-function" id="toc-the-gpt-function" class="nav-link" data-scroll-target="#the-gpt-function">The gpt() Function</a></li>
  <li><a href="#the-gpttxt-function" id="toc-the-gpttxt-function" class="nav-link" data-scroll-target="#the-gpttxt-function">The gpttxt() Function</a></li>
  </ul></li>
  <li><a href="#choosing-the-right-model" id="toc-choosing-the-right-model" class="nav-link" data-scroll-target="#choosing-the-right-model">Choosing the Right Model</a>
  <ul class="collapse">
  <li><a href="#available-models" id="toc-available-models" class="nav-link" data-scroll-target="#available-models">Available Models</a></li>
  <li><a href="#defining-the-gpt-x-model-to-use" id="toc-defining-the-gpt-x-model-to-use" class="nav-link" data-scroll-target="#defining-the-gpt-x-model-to-use">Defining the GPT-X Model to Use</a></li>
  </ul></li>
  <li><a href="#customizing-system-content-prompt" id="toc-customizing-system-content-prompt" class="nav-link" data-scroll-target="#customizing-system-content-prompt">Customizing System Content Prompt</a></li>
  <li><a href="#customizing-api-settings" id="toc-customizing-api-settings" class="nav-link" data-scroll-target="#customizing-api-settings">Customizing API Settings</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Ready to explore beyond ChatGPT?…</p>
<section id="obtain-the-code" class="level2">
<h2 class="anchored" data-anchor-id="obtain-the-code">Obtain the Code</h2>
<p>The code used in this blog post can be accessed in my GitHub Repo:</p>
<p><a href="https://github.com/PeterBloomingdale/gpt">PeterBloomingdale/gpt</a></p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>OpenAI’s GPT models are state-of-the-art language models that have revolutionized the field of natural language processing.</p>
<p>This tutorial provides a guide for using simple and easy to use Python functions to interact with the OpenAI API, enabling you to harness the power of GPT models directly in your IDE terminal and build into your own products.</p>
</section>
<section id="prerequisites" class="level2">
<h2 class="anchored" data-anchor-id="prerequisites">Prerequisites</h2>
<p>Before diving into the tutorial, there are a few prerequisites you’ll need to fulfill in order to successfully use the Python functions provided in the GitHub repository to access the OpenAI API.</p>
<section id="openai-api-key-and-organization-id" class="level3">
<h3 class="anchored" data-anchor-id="openai-api-key-and-organization-id">OpenAI API Key and Organization ID</h3>
<p>To use the OpenAI API, you must have an API key and Organization ID. These credentials allow you to authenticate with the API and access its features. To obtain an API key and Organization ID, follow these steps:</p>
<ol type="1">
<li>Visit the <a href="https://platform.openai.com/">OpenAI Developer Dashboard</a>.</li>
<li>Sign up for an account or log in if you already have one.</li>
<li>Once logged in, navigate to the API Keys section.</li>
<li>Obtain your <strong>API key</strong> and <strong>Organization ID</strong>, as you’ll need them in the next step.</li>
</ol>
</section>
<section id="setting-up-the-secrets.py-file" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-secrets.py-file">Setting Up the secrets.py File</h3>
<p>After obtaining your <strong>API key</strong> and <strong>Organization ID</strong>, you’ll need to create a file named <strong><code>secrets.py</code></strong> in the same directory as the <strong><code>gpt.py</code></strong> file from the GitHub repository. This file will store your API credentials, allowing the Python functions to authenticate with the OpenAI API.</p>
<p>To create the <strong><code>secrets.py</code></strong> file, follow these steps:</p>
<ol type="1">
<li>In the same directory as the <strong><code>gpt.py</code></strong> file, create a new file and name it <strong><code>secrets.py</code></strong>.</li>
<li>Open the <strong><code>secrets.py</code></strong> file in your favorite text editor or IDE.</li>
<li>Define two variables, <strong>API_Key</strong> and <strong>Organization_ID</strong>, with your OpenAI API key and Organization ID as their respective values. Replace <em>‘your_api_key_here’</em> and <em>‘your_organization_id_here’</em> with the actual credentials you obtained from the OpenAI Developer Dashboard. Your <strong><code>secrets.py</code></strong> file should look like this:</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>API_Key <span class="op">=</span> <span class="st">'your_api_key_here'</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Organization_ID <span class="op">=</span> <span class="st">'your_organization_id_here'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="4" type="1">
<li>Save and close the <strong><code>secrets.py</code></strong> file</li>
</ol>
<p>Now that you have your API credentials stored in the <strong><code>secrets.py</code></strong> file, the Python functions will be able to access the OpenAI API, and you can proceed with the rest of the tutorial.</p>
</section>
</section>
<section id="python-functions-overview" class="level2">
<h2 class="anchored" data-anchor-id="python-functions-overview">Python Functions Overview</h2>
<p>In this section, we’ll go over the two primary functions provided in the <strong><code>gpt.py</code></strong> file: <strong><code>gpt()</code></strong> and <strong><code>gpttxt()</code></strong>. These functions allow you to interact with the OpenAI API to generate responses from the GPT model.</p>
<section id="gpt-class" class="level3">
<h3 class="anchored" data-anchor-id="gpt-class">GPT Class</h3>
<p>The GPT class provides a callable function, <strong><code>gpt()</code></strong>, that takes a string as input and returns the generated response from the OpenAI API as a string. This function is ideal for generating responses to single prompts or questions. The code for the GPT class is as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPT:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, question):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span> </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> openai.ChatCompletion.create( </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span>model,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>[</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are the worlds best software engineer."</span>},</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: question},</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            max_tokens<span class="op">=</span><span class="dv">2048</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            top_p<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="gpttxt-class" class="level3">
<h3 class="anchored" data-anchor-id="gpttxt-class">GPTTXT Class</h3>
<p>The GPTTXT class provides a callable function, <strong><code>gpttxt()</code></strong>, that takes a file path (pointing to a .txt file) as input and returns the generated response from the OpenAI API as a string. This function is ideal for generating responses to prompts or questions contained in a text file. The code for the GPTTXT class is as follows:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GPTTXT:</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, input_file_path):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(input_file_path, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>            input_string <span class="op">=</span> f.read()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span>model,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>[</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are the worlds best software engineer."</span>},</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: input_string},</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            temperature<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            max_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            top_p<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            n<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="using-the-functions" class="level2">
<h2 class="anchored" data-anchor-id="using-the-functions">Using the Functions</h2>
<p>In this section, we’ll demonstrate how to use the <strong><code>gpt()</code></strong> and <strong><code>gpttxt()</code></strong> functions from the gpt.py file to generate responses from the OpenAI API.</p>
<section id="the-gpt-function" class="level3">
<h3 class="anchored" data-anchor-id="the-gpt-function">The gpt() Function</h3>
<p>To use the <strong><code>gpt()</code></strong> function, follow these steps:</p>
<ol type="1">
<li>First, ensure that the <strong><code>gpt.py</code></strong> file is in your project directory.</li>
<li>In your main Python script or terminal, import the <strong>gpt</strong> instance from the <strong><code>gpt.py</code></strong> file:</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gpt <span class="im">import</span> gpt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li>Call the <strong><code>gpt()</code></strong> function with the desired input string (question or prompt). For example, to generate a response to the prompt “What is the meaning of life?”, use the following code:</li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> gpt(<span class="st">"What is the meaning of life?"</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="the-gpttxt-function" class="level3">
<h3 class="anchored" data-anchor-id="the-gpttxt-function">The gpttxt() Function</h3>
<p>To use the <strong><code>gpttxt()</code></strong> function, follow these steps:</p>
<ol type="1">
<li>Ensure that the <strong><code>gpt.py</code></strong> file is in your project directory.</li>
<li>In your main Python script or terminal, import the <strong>gpttxt</strong> instance from the <strong><code>gpt.py</code></strong> file:</li>
</ol>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gpt <span class="im">import</span> gpttxt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li>Insert text of interest into the <strong><code>input.txt</code></strong> file</li>
<li>Call the <strong><code>gpttxt()</code></strong> function with the name of the text file as its argument. For example, to generate a response based on the content of the <strong><code>input.txt</code></strong> file, use the following code:</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> gpttxt(<span class="st">'input.txt'</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note that instead of creating and printing a variable (e.g.&nbsp;response), you can directly use the function in the terminal.</p>
</section>
</section>
<section id="choosing-the-right-model" class="level2">
<h2 class="anchored" data-anchor-id="choosing-the-right-model">Choosing the Right Model</h2>
<p>When using the OpenAI API, it’s essential to choose the right model to generate high-quality responses. In this section, we’ll discuss how to select the appropriate model for your use case and how to configure the <strong><code>gpt()</code></strong> and <strong><code>gpttxt()</code></strong> functions to use the chosen model.</p>
<section id="available-models" class="level3">
<h3 class="anchored" data-anchor-id="available-models">Available Models</h3>
<p>OpenAI offers several GPT models that you can use with the API. Each model has its own characteristics and capabilities. Some available models are:</p>
<ul>
<li><strong>gpt-3.5-turbo</strong>: The most advanced model, offering excellent response quality and speed. This model is recommended for most use cases.</li>
<li><strong>text-davinci-002</strong>: A powerful model that can generate high-quality responses but is slower and more expensive than gpt-3.5-turbo.</li>
<li><strong>text-curie-002</strong>: A model that offers a balance between response quality and cost.</li>
<li><strong>text-babbage-002</strong>: A model that generates good responses at a lower cost, suitable for applications with tight budgets.</li>
<li><strong>text-ada-002</strong>: The lowest-cost model that still produces reasonable responses, ideal for cost-sensitive applications.</li>
</ul>
<p>You can find more information about the available models in <a href="https://platform.openai.com/docs/models">OpenAI API model documentation</a>.</p>
</section>
<section id="defining-the-gpt-x-model-to-use" class="level3">
<h3 class="anchored" data-anchor-id="defining-the-gpt-x-model-to-use">Defining the GPT-X Model to Use</h3>
<p>By default, both functions use the <strong>gpt-3.5-turbo</strong> model, which is recommended for most use cases. However, you can easily change the model used by these functions to suit your specific needs.</p>
<p>To change the model, modify the model variable in the <code>__call__</code> method of the GPT and GPTTXT classes in the <strong><code>gpt.py</code></strong> file. For example, to use the <strong>text-curie-002</strong> model, change the following lines:</p>
<p>In the GPT and GPTTXT classes:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">"gpt-3.5-turbo"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>to</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">"text-curie-002"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After making these changes, the <strong><code>gpt()</code></strong> and <strong><code>gpttxt()</code></strong> functions will use the specified model when making requests to the OpenAI API.</p>
</section>
</section>
<section id="customizing-system-content-prompt" class="level2">
<h2 class="anchored" data-anchor-id="customizing-system-content-prompt">Customizing System Content Prompt</h2>
<p>In the API request, you’ll notice that there is a system content prompt which is defined as:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>messages<span class="op">=</span>[</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are the worlds best software engineer."</span>},</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: question},</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>],</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The system content prompt provides initial context or instructions for the AI model. In this case, the prompt is set to “You are the worlds best software engineer,” which helps set the tone and context for the AI’s response. It informs the AI model to respond as if it is an expert in software engineering.</p>
<p>You can customize the system content prompt to better suit your needs or to set a different context for the AI model. For example, if you want the AI to respond as a knowledgeable data scientist, you can change the system content message to:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>{<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are an expert data scientist."</span>},</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or, if you want the AI to provide beginner-friendly explanations, you can change the message to:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>{<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are a software engineer who explains complex topics in simple terms."</span>},</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To modify the system content prompt, simply replace the content value in the messages list with your desired context or instruction. Keep in mind that the AI’s response may vary depending on the context provided, so it’s essential to test and refine your prompt to achieve the desired output.</p>
</section>
<section id="customizing-api-settings" class="level2">
<h2 class="anchored" data-anchor-id="customizing-api-settings">Customizing API Settings</h2>
<p>In this section, we’ll briefly cover how to customize API settings to fine-tune the behavior of the <strong><code>gpt()</code></strong> and <strong><code>gpttxt()</code></strong> functions when making requests to the OpenAI API. Each of the following parameters can be adjusted within the <code>openai.ChatCompletion.create</code> method.</p>
<ul>
<li><p><strong>temperature</strong>: Controls the creativity of the generated responses. Higher values result in more randomness, while lower values make responses more focused and deterministic.</p></li>
<li><p><strong>max_tokens</strong>: Controls the length of generated responses. Set a higher value for longer responses or a lower value for shorter responses.</p></li>
<li><p><strong>top_p</strong>: Controls the diversity of generated responses. Lower values promote more diverse responses by filtering out less probable tokens.</p></li>
<li><p><strong>n</strong>: Generates <strong>n</strong> number of responses. Useful if multiple responses are desired.</p></li>
<li><p><strong>presence_penalty</strong>: Discourages the model from repeating previous responses by penalizing tokens that have already been generated in the conversation. Higher values reduce repetition. Default is 0, ranges between 0-1.</p></li>
<li><p><strong>frequency_penalty</strong>: Encourages the model to generate more varied responses by penalizing tokens that have been used frequently in the conversation. Higher values reduce the frequency of common phrases. Default is 0, ranges between 0-1.</p></li>
<li><p><strong>stop</strong>: A list of tokens that, when generated by the model, indicate that the response is complete and the model should stop generating additional tokens.</p></li>
<li><p><strong>echo</strong>: A boolean parameter that, when set to True, causes the model to include the user’s message in its response.</p></li>
<li><p><strong>prompt_token</strong>: A string that is added at the beginning of the user’s message when the echo parameter is True. This can be useful for formatting the output or providing additional context to the model.</p></li>
<li><p><strong>response_prefix</strong>: A string that is added to the beginning of the model’s response. This can be useful for formatting the output or separating multiple responses when n is greater than 1.</p></li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Hope this was helpful!</p>
<p>If you made it this far, a hot topic right now is <strong>AutoGPTs</strong>, which I think the buzz has not hit mainstream just yet. In short, I currently view AutoGPTs as novel architectural designs linking up multiple LLMs together to create an <em>“emergent-like”</em> behavior to solve tasks.</p>
<p>Auto-GPTs can also be defined as seamlessly connecting LLM “thoughts” to autonomously accomplish any objective you assign.</p>
<p>The Paper and Twitter post that started it all:</p>
<ul>
<li><a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/">AutoGPT Paper</a></li>
<li><a href="https://twitter.com/yoheinakajima/status/1640934493489070080?lang=en">Twitter Post</a></li>
</ul>
<p>A few very fast growing GitHub projects emerged around this concept:</p>
<p><img src="AutoGPT.png" class="img-fluid"></p>
<ul>
<li><a href="https://github.com/Significant-Gravitas/Auto-GPT">Significant-Gravitas/Auto-GPT</a></li>
<li><a href="https://github.com/reworkd/AgentGPT">reworkd/AgentGPT</a></li>
<li><a href="https://github.com/yoheinakajima/babyagi">yoheinakajima/babyagi</a></li>
</ul>
<hr>
<p><em>Music Currently on Repeat: <a href="https://open.spotify.com/album/0KKSwf9fKCBIBuQyOcfq3w?si=MZ2EQcuOQTSS07vZInZisQ">Gaming Chill Music</a></em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'alternate';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
      <div class="nav-footer-center">
        <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright © 2023 PeterBloomingdale.com  
  </li>  
</ul>
      </div>
  </div>
</footer>



</body></html>